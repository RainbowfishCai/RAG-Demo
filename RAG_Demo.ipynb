{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzffAJVe92qP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.documents import Document\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Collection: Financial News, Earnings Calls, Reports are stored in the databse, in txt files"
      ],
      "metadata": {
        "id": "cdHzyey__Vnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Coding"
      ],
      "metadata": {
        "id": "oYYEJSIb_g9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Text-splitting, Embedding Creation, Vector Database"
      ],
      "metadata": {
        "id": "Fn_tiJCk_kKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'API KEY'\n",
        "def process_in_batches(documents, embeddings, batch_size): #Store the Embeddings in Vector Database in batches\n",
        "    vector_store = None\n",
        "    i = 0\n",
        "    while i < len(documents):\n",
        "      batch = documents[i:i+len(documents) // batch_size]\n",
        "      i += len(documents) // batch_size\n",
        "      batch_vector_store = FAISS.from_documents(batch, embeddings)\n",
        "      if vector_store is None:\n",
        "        vector_store = batch_vector_store\n",
        "      else:\n",
        "        vector_store.merge_from(batch_vector_store)\n",
        "    return vector_store\n",
        "\n",
        "\n",
        "myfolder = 'Data Folder'\n",
        "file_path = os.path.join(myfolder, 'faiss_index_20')\n",
        "if os.path.exists(file_path):\n",
        "  print(f\"The file already exists in the folder '{myfolder}'.\")\n",
        "  continue\n",
        "else:\n",
        "  #Create the Emebeddings (3-small/3-large)\n",
        "  myembeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "  #Probably: Text splitter\n",
        "  text_splitter_20 = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=16000, #Length of each chunk\n",
        "    chunk_overlap=800 #Length of the overlap paragraph, avoid information missing\n",
        "  )\n",
        "  #Check the available loaders\n",
        "  #loader = DirectoryLoader(myfolder, glob='*.txt')\n",
        "  text_loader_kwargs = {\"autodetect_encoding\": True}\n",
        "  loader = DirectoryLoader(myfolder, glob='*.txt', loader_cls=TextLoader, loader_kwargs=text_loader_kwargs, silent_errors=True)\n",
        "  docs = loader.load()\n",
        "  documents_20 = text_splitter_20.split_documents(docs)\n",
        "  #Create the Vector Store\n",
        "  vector_20 = process_in_batches(documents_20, myembeddings,10)\n",
        "  vector_20.save_local(f\"{myfolder}/faiss_index_20\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iBIxsnM4_oBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Prompt Design: CoT Prompts (Role Description, Scoring Rubrics, Examples)"
      ],
      "metadata": {
        "id": "NmFfQIMIBqaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "factor = 'Prompt name'\n",
        "file_path = 'Prompt File'\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "except UnicodeDecodeError:\n",
        "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
        "        content = file.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "id": "lRJDfTMCCYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Naive RAG Model\n",
        "(In total 5 factors. For each factor, n paragraphs of context is retrieved from database that are most relevant with the query)"
      ],
      "metadata": {
        "id": "ouGPQb53E3U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model='gpt-4o-mini')\n",
        "embeddings_small = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "myfolder = f'data file for specific company at specific year'\n",
        "file_path = os.path.join(myfolder, 'faiss_index_20')\n",
        "if os.path.exists(file_path):\n",
        "  #Load vector from the drive\n",
        "  myvector_20 = FAISS.load_local(f\"{myfolder}/faiss_index_20\", embeddings_small,allow_dangerous_deserialization=True)\n",
        "  retriever = myvector_20.as_retriever()\n",
        "  score_list = []\n",
        "  for i in range(5):\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "      #Prompt Design, Confiential\n",
        "    ])\n",
        "    #Connect LLM and prompt\n",
        "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "    #make the vectors into retriever\n",
        "    #input prompt for the retriever to retrieve dataï¼Œoutput the data to the chain\n",
        "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
        "    #content is the prompt\n",
        "    response = retrieval_chain.invoke({\n",
        "        \"input\":  ,\n",
        "        \"year\":\n",
        "    })\n",
        "  score = score_list[0] * 0.3 + score_list[1] * 0.2 + score_list[2] * 0.05 + score_list[3] * 0.15 + score_list[4] * 0.30\n",
        "  company_score_list.append(score)\n",
        "  print(company, year, 'score: ', score, 'Market: ', score_list[0], 'Product: ', score_list[1], 'Operation: ', score_list[2], 'Strategy: ', score_list[3], 'Adaptability: ', score_list[4])\n",
        "else:\n",
        "  company_score_list.append(-1)\n",
        "  print(company, year, 'No Data')\n"
      ],
      "metadata": {
        "id": "PT2dBt7eBcmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Advanced RAG model (re-rank, query rewriting, AI-agent, Finetune)"
      ],
      "metadata": {
        "id": "VbO_PQ_8GaXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#re-rank\n",
        "from FlagEmbedding import FlagReranker\n",
        "# Re-rank according to similarity scores\n",
        "    reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)\n",
        "    # List to store scores and documents\n",
        "    scored_docs = []\n",
        "    # Calculate the reranking score for each document\n",
        "    for doc in retrieved_docs:\n",
        "        score = reranker.compute_score([content, str(doc)], normalize=True)  # Compute the score for the document\n",
        "        scored_docs.append((doc, score))  # Store the document and its score\n",
        "    # Sort the documents by score in descending order\n",
        "    scored_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "    # Take the top 4 documents based on the score\n",
        "    top_4_docs = [doc for doc, score in scored_docs[:4]]\n",
        "    # Create a new FAISS vector store with the top 4 documents\n",
        "    new_vector_store = FAISS.from_documents(top_4_docs, embeddings_small)\n",
        "    # Create a new retriever based on the top 4 documents\n",
        "    refined_retriever = new_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "2fRzv1UTGpqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#query rewriting\n",
        "from langchain.chains import HypotheticalDocumentEmbedder, LLMChain\n",
        "from scipy.spatial.distance import cosine\n",
        "#Prompt Design\n",
        "    multi_llm = ChatOpenAI(n=4)\n",
        "\n",
        "    embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
        "        multi_llm, embeddings_small, \"web_search\"\n",
        "    )\n",
        "\n",
        "    # Use the embedding function to get relevant documents\n",
        "    query_embedding = embeddings.embed_query(content)\n",
        "\n",
        "    retrieved_docs = retriever.get_relevant_documents(content)\n",
        "\n",
        "    # Re-rank according to similarity scores\n",
        "\n",
        "    # List to store scores and documents\n",
        "    scored_docs = []\n",
        "    # Calculate the reranking score for each document\n",
        "    for doc in retrieved_docs:\n",
        "      doc_embedding = embeddings.embed_documents(doc.page_content)[0]  # get document embeddings\n",
        "      # calculate similarity\n",
        "      score = 1-cosine(query_embedding, doc_embedding)  # use cosine similarity\n",
        "      scored_docs.append((doc, score))\n",
        "      print(score)\n",
        "    # Sort the documents by score in descending order\n",
        "    scored_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "    # Take the top 4 documents based on the score\n",
        "    top_4_docs = [doc for doc, score in scored_docs[:4]]\n",
        "    # Create a new FAISS vector store with the top 4 documents\n",
        "    new_vector_store = FAISS.from_documents(top_4_docs, embeddings_small)\n",
        "    # Create a new retriever based on the top 4 documents\n",
        "    refined_retriever = new_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "_q63OdiTHvNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finetune\n",
        "\n",
        "#Set-up Training data and Validation data\n",
        "import json\n",
        "np.random.seed(0)\n",
        "yearlist = list(range(2014,2024))\n",
        "mycolumns = scoredf.columns\n",
        "training_data = []\n",
        "for promptidx in range(len(promptlist)):\n",
        "  for rowidx in range(len(scoredf)//4):\n",
        "    system_message = {\"role\": \"system\", \"content\": promptlist[promptidx]}\n",
        "    user_message = {\"role\": \"user\", \"content\": f'Tell me the {mycolumns[promptidx+1]} score of {scoredf.iloc[rowidx, 0]} in year {yearlist[rowidx % 10]}.'}\n",
        "    if scoredf.iloc[rowidx, promptidx+1] < 0:\n",
        "      continue\n",
        "    randomscore = scoredf.iloc[rowidx, promptidx+1] + np.random.randint(-10,10)\n",
        "    if randomscore < 0:\n",
        "      randomscore = 0\n",
        "    if randomscore > 100:\n",
        "      randomscore = 100\n",
        "    assistant_message = {\"role\": \"assistant\", \"content\": f'the score of {scoredf.iloc[rowidx, 0]} in year {yearlist[rowidx % 10]} for {mycolumns[promptidx+1]} is {randomscore}.'}\n",
        "    messages = [system_message, user_message, assistant_message]\n",
        "    training_data.append({\"messages\": [system_message, user_message, assistant_message]})\n",
        "def write_to_jsonl_file(data, file_path):\n",
        "    \"\"\"\n",
        "    Write the data to a .jsonl file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'w') as f:\n",
        "        for entry in data:\n",
        "            json.dump(entry, f)  # Convert the dictionary to JSON and write it\n",
        "            f.write('\\n')  # Ensure each JSON object is on a new line\n",
        "    print(f\"Data successfully written to {file_path}\")\n",
        "file_path = \"/content/drive/My Drive/24 Summer - RAGer/Code/RAG Pipeline/Pipeline Phase 2/Finetune Tests/automated_large_training_data_CEO.jsonl\"\n",
        "write_to_jsonl_file(training_data, file_path)\n",
        "\n",
        "#Create Fine-tune model in OpenAI"
      ],
      "metadata": {
        "id": "2zjClO40IIvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI Agent\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"API Key\"\n",
        "search = TavilySearchResults()\n",
        "tools = [search, retriever_tool]\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "response = agent_executor.invoke({\n",
        "        \"input\": content,\n",
        "        \"year\": year,\n",
        "        'context': context\n",
        "})"
      ],
      "metadata": {
        "id": "Ej6fhZtOIjWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Combined Structure"
      ],
      "metadata": {
        "id": "2NMy_QyxJIaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myfolder = f'data file for specific company at specific year'\n",
        "llm = ChatOpenAI(temperature=0, model='fine-tune model')\n",
        "embeddings_small = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "#Load vector from the drive\n",
        "if os.path.exists(f\"{myfolder}/faiss_index_20/index.faiss\"):\n",
        "  myvector_20 = FAISS.load_local(f\"{myfolder}/faiss_index_20\", embeddings_small,allow_dangerous_deserialization=True)\n",
        "  retriever = myvector_20.as_retriever()\n",
        "\n",
        "  #Prompt Design\n",
        "  multi_llm = ChatOpenAI(n=4)\n",
        "\n",
        "  embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
        "      multi_llm, embeddings_small, \"web_search\"\n",
        "  )\n",
        "\n",
        "  # Use the embedding function to get relevant documents\n",
        "  query_embedding = embeddings.embed_query(content)\n",
        "\n",
        "  retrieved_docs = retriever.get_relevant_documents(content)\n",
        "\n",
        "  # Re-rank according to similarity scores\n",
        "\n",
        "  # List to store scores and documents\n",
        "  scored_docs = []\n",
        "  # Calculate the reranking score for each document\n",
        "  for doc in retrieved_docs:\n",
        "    doc_embedding = embeddings.embed_documents(doc.page_content)[0]  # get document embeddings\n",
        "    # calculate similarity\n",
        "    score = 1-cosine(query_embedding, doc_embedding)  # use cosine similarity\n",
        "    scored_docs.append((doc, score))\n",
        "    print(score)\n",
        "  # Sort the documents by score in descending order\n",
        "  scored_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "  # Take the top 4 documents based on the score\n",
        "  top_4_docs = [doc for doc, score in scored_docs[:4]]\n",
        "  # Create a new FAISS vector store with the top 4 documents\n",
        "  new_vector_store = FAISS.from_documents(top_4_docs, embeddings_small)\n",
        "  # Create a new retriever based on the top 4 documents\n",
        "  refined_retriever = new_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "  retriever_tool = create_retriever_tool(refined_retriever,'Finance_Data_File_Retriever', 'Retrieve similar files from data base according to user message.')\n",
        "  tools = [search, retriever_tool]\n",
        "\n",
        "  #Prompt Design\n",
        "  score_list = []\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      'Prompt with Context, query and year/company information'\n",
        "  ])\n",
        "  prompt.partial(agent_scratchpad=lambda x: x)\n",
        "\n",
        "  #Connect LLM and prompt\n",
        "  document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "  agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "  agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "  relevant_docs = retriever.get_relevant_documents(content)\n",
        "  context = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  response = agent_executor.invoke({\n",
        "      \"input\": content,\n",
        "      \"year\": year,\n",
        "      'context': context\n",
        "  })\n",
        "\n",
        "  output_parser = StrOutputParser()\n",
        "  score_chat_history = [HumanMessage(content=content), AIMessage(content=response[\"output\"])]\n",
        "  score_prompt = ChatPromptTemplate.from_messages([\n",
        "      MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "      (\"user\", f\"{input}\"),\n",
        "      (\"system\", 'Only return one final score number, do not return anything else!')])\n",
        "  score_chain = score_prompt | llm | output_parser\n",
        "  response3 = score_chain.invoke({\n",
        "      \"chat_history\": score_chat_history,\n",
        "  })\n",
        "  score_list.append(response3)\n",
        "\n",
        "  print(company, year)\n",
        "  print('Score: ', score_list[0])\n",
        "\n",
        "  # Append the results to the list\n",
        "  results.append({\n",
        "      'Company': company,\n",
        "      'Year': year,\n",
        "      'If retrieve': 'Yes',\n",
        "      'Score': score_list[0],\n",
        "  })"
      ],
      "metadata": {
        "id": "yb9jkuO0JLNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}